digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label=<X<SUB>17</SUB> &le; 1.5<br/>entropy = 1.0<br/>samples = 39651<br/>value = [19825.5, 19825.5]<br/>class = 1>, fillcolor="#ffffff"] ;
1 [label=<X<SUB>16</SUB> &le; 0.5<br/>entropy = 0.786<br/>samples = 20969<br/>value = [10530.929, 3225.577]<br/>class = 0>, fillcolor="#eda876"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<entropy = 0.0<br/>samples = 9412<br/>value = [4736.1, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
1 -> 2 ;
3 [label=<X<SUB>33</SUB> &le; 0.5<br/>entropy = 0.941<br/>samples = 11557<br/>value = [5794.829, 3225.577]<br/>class = 0>, fillcolor="#f3c7a7"] ;
1 -> 3 ;
4 [label=<X<SUB>32</SUB> &le; 2.5<br/>entropy = 0.802<br/>samples = 9695<br/>value = [4868.441, 1573.452]<br/>class = 0>, fillcolor="#edaa79"] ;
3 -> 4 ;
5 [label=<X<SUB>4</SUB> &le; 0.5<br/>entropy = 0.848<br/>samples = 8266<br/>value = [4149.371, 1573.452]<br/>class = 0>, fillcolor="#efb184"] ;
4 -> 5 ;
6 [label=<X<SUB>26</SUB> &le; 3.5<br/>entropy = 0.611<br/>samples = 3539<br/>value = [1778.805, 314.69]<br/>class = 0>, fillcolor="#ea975c"] ;
5 -> 6 ;
7 [label=<entropy = 0.0<br/>samples = 1445<br/>value = [727.121, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
6 -> 7 ;
8 [label=<X<SUB>5</SUB> &le; 2.5<br/>entropy = 0.779<br/>samples = 2094<br/>value = [1051.684, 314.69]<br/>class = 0>, fillcolor="#eda774"] ;
6 -> 8 ;
9 [label=<X<SUB>1</SUB> &le; 0.5<br/>entropy = 0.917<br/>samples = 1262<br/>value = [633.023, 314.69]<br/>class = 0>, fillcolor="#f2c09b"] ;
8 -> 9 ;
10 [label=<entropy = 0.986<br/>samples = 832<br/>value = [416.648, 314.69]<br/>class = 0>, fillcolor="#f9e0cf"] ;
9 -> 10 ;
11 [label=<entropy = 0.0<br/>samples = 430<br/>value = [216.375, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
9 -> 11 ;
12 [label=<entropy = 0.0<br/>samples = 832<br/>value = [418.661, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
8 -> 12 ;
13 [label=<X<SUB>10</SUB> &le; 1.5<br/>entropy = 0.931<br/>samples = 4727<br/>value = [2370.566, 1258.762]<br/>class = 0>, fillcolor="#f3c4a2"] ;
5 -> 13 ;
14 [label=<X<SUB>7</SUB> &le; 2.5<br/>entropy = 0.973<br/>samples = 3714<br/>value = [1860.826, 1258.762]<br/>class = 0>, fillcolor="#f7d6bf"] ;
13 -> 14 ;
15 [label=<X<SUB>27</SUB> &le; 2.5<br/>entropy = 0.99<br/>samples = 3199<br/>value = [1601.679, 1258.762]<br/>class = 0>, fillcolor="#f9e4d5"] ;
14 -> 15 ;
16 [label=<entropy = 0.971<br/>samples = 1052<br/>value = [524.332, 786.726]<br/>class = 1>, fillcolor="#bddef6"] ;
15 -> 16 ;
17 [label=<entropy = 0.887<br/>samples = 2147<br/>value = [1077.347, 472.036]<br/>class = 0>, fillcolor="#f0b890"] ;
15 -> 17 ;
18 [label=<entropy = 0.0<br/>samples = 515<br/>value = [259.147, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
14 -> 18 ;
19 [label=<entropy = 0.0<br/>samples = 1013<br/>value = [509.74, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
13 -> 19 ;
20 [label=<entropy = 0.0<br/>samples = 1429<br/>value = [719.07, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
4 -> 20 ;
21 [label=<X<SUB>23</SUB> &le; 4.5<br/>entropy = 0.942<br/>samples = 1862<br/>value = [926.388, 1652.125]<br/>class = 1>, fillcolor="#a8d4f4"] ;
3 -> 21 ;
22 [label=<X<SUB>5</SUB> &le; 1.5<br/>entropy = 0.762<br/>samples = 726<br/>value = [357.271, 1258.762]<br/>class = 1>, fillcolor="#71b9ec"] ;
21 -> 22 ;
23 [label=<entropy = 0.0<br/>samples = 114<br/>value = [57.365, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
22 -> 23 ;
24 [label=<X<SUB>20</SUB> &le; 0.5<br/>entropy = 0.706<br/>samples = 612<br/>value = [299.906, 1258.762]<br/>class = 1>, fillcolor="#68b4eb"] ;
22 -> 24 ;
25 [label=<X<SUB>16</SUB> &le; 1.5<br/>entropy = 0.651<br/>samples = 518<br/>value = [252.605, 1258.762]<br/>class = 1>, fillcolor="#61b1ea"] ;
24 -> 25 ;
26 [label=<entropy = 0.0<br/>samples = 60<br/>value = [30.192, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
25 -> 26 ;
27 [label=<X<SUB>32</SUB> &le; 1.5<br/>entropy = 0.61<br/>samples = 458<br/>value = [222.414, 1258.762]<br/>class = 1>, fillcolor="#5caeea"] ;
25 -> 27 ;
28 [label=<entropy = 0.577<br/>samples = 414<br/>value = [200.273, 1258.762]<br/>class = 1>, fillcolor="#59ade9"] ;
27 -> 28 ;
29 [label=<entropy = 0.0<br/>samples = 44<br/>value = [22.141, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
27 -> 29 ;
30 [label=<entropy = 0.0<br/>samples = 94<br/>value = [47.301, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
24 -> 30 ;
31 [label=<X<SUB>2</SUB> &le; 1.5<br/>entropy = 0.976<br/>samples = 1136<br/>value = [569.117, 393.363]<br/>class = 0>, fillcolor="#f7d8c2"] ;
21 -> 31 ;
32 [label=<X<SUB>27</SUB> &le; 1.5<br/>entropy = 0.976<br/>samples = 547<br/>value = [272.733, 393.363]<br/>class = 1>, fillcolor="#c2e1f7"] ;
31 -> 32 ;
33 [label=<X<SUB>32</SUB> &le; 0.5<br/>entropy = 0.495<br/>samples = 60<br/>value = [28.682, 236.018]<br/>class = 1>, fillcolor="#51a9e8"] ;
32 -> 33 ;
34 [label=<entropy = 0.0<br/>samples = 18<br/>value = [9.058, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
33 -> 34 ;
35 [label=<X<SUB>4</SUB> &le; 0.5<br/>entropy = 0.391<br/>samples = 42<br/>value = [19.625, 236.018]<br/>class = 1>, fillcolor="#49a5e7"] ;
33 -> 35 ;
36 [label=<entropy = 0.0<br/>samples = 12<br/>value = [6.038, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
35 -> 36 ;
37 [label=<entropy = 0.305<br/>samples = 30<br/>value = [13.586, 236.018]<br/>class = 1>, fillcolor="#44a3e6"] ;
35 -> 37 ;
38 [label=<X<SUB>9</SUB> &le; 2.5<br/>entropy = 0.966<br/>samples = 487<br/>value = [244.051, 157.345]<br/>class = 0>, fillcolor="#f6d2b9"] ;
32 -> 38 ;
39 [label=<X<SUB>28</SUB> &le; 3.5<br/>entropy = 0.986<br/>samples = 239<br/>value = [119.258, 157.345]<br/>class = 1>, fillcolor="#cfe7f9"] ;
38 -> 39 ;
40 [label=<entropy = 0.0<br/>samples = 118<br/>value = [59.377, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
39 -> 40 ;
41 [label=<entropy = 0.849<br/>samples = 121<br/>value = [59.881, 157.345]<br/>class = 1>, fillcolor="#84c2ef"] ;
39 -> 41 ;
42 [label=<entropy = 0.0<br/>samples = 248<br/>value = [124.793, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
38 -> 42 ;
43 [label=<entropy = 0.0<br/>samples = 589<br/>value = [296.384, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
31 -> 43 ;
44 [label=<X<SUB>33</SUB> &le; 0.5<br/>entropy = 0.942<br/>samples = 18682<br/>value = [9294.571, 16599.923]<br/>class = 1>, fillcolor="#a8d4f4"] ;
0 -> 44 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
45 [label=<X<SUB>21</SUB> &le; 1.0<br/>entropy = 0.998<br/>samples = 13357<br/>value = [6674.419, 7316.554]<br/>class = 1>, fillcolor="#eef6fd"] ;
44 -> 45 ;
46 [label=<X<SUB>0</SUB> &le; 0.5<br/>entropy = 0.978<br/>samples = 9180<br/>value = [4598.727, 3225.577]<br/>class = 0>, fillcolor="#f7d9c4"] ;
45 -> 46 ;
47 [label=<entropy = 0.0<br/>samples = 1523<br/>value = [766.371, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
46 -> 47 ;
48 [label=<X<SUB>17</SUB> &le; 2.5<br/>entropy = 0.995<br/>samples = 7657<br/>value = [3832.356, 3225.577]<br/>class = 0>, fillcolor="#fbebe0"] ;
46 -> 48 ;
49 [label=<X<SUB>2</SUB> &le; 1.5<br/>entropy = 0.738<br/>samples = 2383<br/>value = [1197.108, 314.69]<br/>class = 0>, fillcolor="#eca26d"] ;
48 -> 49 ;
50 [label=<entropy = 0.0<br/>samples = 1868<br/>value = [939.974, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
49 -> 50 ;
51 [label=<X<SUB>5</SUB> &le; 2.5<br/>entropy = 0.993<br/>samples = 515<br/>value = [257.134, 314.69]<br/>class = 1>, fillcolor="#dbedfa"] ;
49 -> 51 ;
52 [label=<entropy = 0.0<br/>samples = 334<br/>value = [168.068, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
51 -> 52 ;
53 [label=<X<SUB>7</SUB> &le; 1.5<br/>entropy = 0.761<br/>samples = 181<br/>value = [89.066, 314.69]<br/>class = 1>, fillcolor="#71b9ec"] ;
51 -> 53 ;
54 [label=<entropy = 0.0<br/>samples = 85<br/>value = [42.772, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
53 -> 54 ;
55 [label=<entropy = 0.553<br/>samples = 96<br/>value = [46.294, 314.69]<br/>class = 1>, fillcolor="#56abe9"] ;
53 -> 55 ;
56 [label=<X<SUB>23</SUB> &le; 4.5<br/>entropy = 0.998<br/>samples = 5274<br/>value = [2635.248, 2910.887]<br/>class = 1>, fillcolor="#ecf6fd"] ;
48 -> 56 ;
57 [label=<X<SUB>31</SUB> &le; 0.5<br/>entropy = 0.924<br/>samples = 1703<br/>value = [846.379, 1652.125]<br/>class = 1>, fillcolor="#9ecff2"] ;
56 -> 57 ;
58 [label=<X<SUB>6</SUB> &le; 1.5<br/>entropy = 0.886<br/>samples = 1457<br/>value = [722.592, 1652.125]<br/>class = 1>, fillcolor="#90c8f0"] ;
57 -> 58 ;
59 [label=<entropy = 0.858<br/>samples = 1311<br/>value = [649.125, 1652.125]<br/>class = 1>, fillcolor="#87c4ef"] ;
58 -> 59 ;
60 [label=<entropy = 0.0<br/>samples = 146<br/>value = [73.467, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
58 -> 60 ;
61 [label=<entropy = 0.0<br/>samples = 246<br/>value = [123.787, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
57 -> 61 ;
62 [label=<X<SUB>5</SUB> &le; 1.5<br/>entropy = 0.978<br/>samples = 3571<br/>value = [1788.869, 1258.762]<br/>class = 0>, fillcolor="#f7dac4"] ;
56 -> 62 ;
63 [label=<X<SUB>25</SUB> &le; 0.5<br/>entropy = 0.798<br/>samples = 254<br/>value = [125.296, 393.363]<br/>class = 1>, fillcolor="#78bced"] ;
62 -> 63 ;
64 [label=<entropy = 0.513<br/>samples = 106<br/>value = [50.823, 393.363]<br/>class = 1>, fillcolor="#53aae8"] ;
63 -> 64 ;
65 [label=<entropy = 0.0<br/>samples = 148<br/>value = [74.473, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
63 -> 65 ;
66 [label=<X<SUB>27</SUB> &le; 2.5<br/>entropy = 0.927<br/>samples = 3317<br/>value = [1663.573, 865.399]<br/>class = 0>, fillcolor="#f3c3a0"] ;
62 -> 66 ;
67 [label=<entropy = 0.0<br/>samples = 895<br/>value = [450.362, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
66 -> 67 ;
68 [label=<entropy = 0.98<br/>samples = 2422<br/>value = [1213.211, 865.399]<br/>class = 0>, fillcolor="#f8dbc6"] ;
66 -> 68 ;
69 [label=<X<SUB>21</SUB> &le; 4.5<br/>entropy = 0.922<br/>samples = 4177<br/>value = [2075.692, 4090.976]<br/>class = 1>, fillcolor="#9dcff2"] ;
45 -> 69 ;
70 [label=<X<SUB>17</SUB> &le; 3.5<br/>entropy = 0.84<br/>samples = 3046<br/>value = [1506.575, 4090.976]<br/>class = 1>, fillcolor="#82c1ef"] ;
69 -> 70 ;
71 [label=<X<SUB>32</SUB> &le; 3.5<br/>entropy = 0.731<br/>samples = 2022<br/>value = [992.81, 3854.958]<br/>class = 1>, fillcolor="#6cb6ec"] ;
70 -> 71 ;
72 [label=<X<SUB>7</SUB> &le; 1.5<br/>entropy = 0.691<br/>samples = 1789<br/>value = [875.565, 3854.958]<br/>class = 1>, fillcolor="#66b3eb"] ;
71 -> 72 ;
73 [label=<X<SUB>19</SUB> &le; 2.5<br/>entropy = 0.596<br/>samples = 986<br/>value = [478.038, 2832.214]<br/>class = 1>, fillcolor="#5aaee9"] ;
72 -> 73 ;
74 [label=<entropy = 0.57<br/>samples = 911<br/>value = [440.298, 2832.214]<br/>class = 1>, fillcolor="#58ace9"] ;
73 -> 74 ;
75 [label=<entropy = 0.0<br/>samples = 75<br/>value = [37.74, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
73 -> 75 ;
76 [label=<X<SUB>19</SUB> &le; 0.5<br/>entropy = 0.855<br/>samples = 803<br/>value = [397.526, 1022.744]<br/>class = 1>, fillcolor="#86c3ef"] ;
72 -> 76 ;
77 [label=<entropy = 0.913<br/>samples = 321<br/>value = [161.023, 78.673]<br/>class = 0>, fillcolor="#f2bf9a"] ;
76 -> 77 ;
78 [label=<entropy = 0.723<br/>samples = 482<br/>value = [236.503, 944.071]<br/>class = 1>, fillcolor="#6bb6ec"] ;
76 -> 78 ;
79 [label=<entropy = 0.0<br/>samples = 233<br/>value = [117.245, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
71 -> 79 ;
80 [label=<X<SUB>2</SUB> &le; 2.5<br/>entropy = 0.899<br/>samples = 1024<br/>value = [513.765, 236.018]<br/>class = 0>, fillcolor="#f1bb94"] ;
70 -> 80 ;
81 [label=<entropy = 0.0<br/>samples = 477<br/>value = [240.025, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
80 -> 81 ;
82 [label=<X<SUB>7</SUB> &le; 2.5<br/>entropy = 0.996<br/>samples = 547<br/>value = [273.74, 236.018]<br/>class = 0>, fillcolor="#fbeee4"] ;
80 -> 82 ;
83 [label=<X<SUB>32</SUB> &le; 1.5<br/>entropy = 0.934<br/>samples = 256<br/>value = [127.309, 236.018]<br/>class = 1>, fillcolor="#a4d2f3"] ;
82 -> 83 ;
84 [label=<entropy = 0.829<br/>samples = 169<br/>value = [83.531, 236.018]<br/>class = 1>, fillcolor="#7fc0ee"] ;
83 -> 84 ;
85 [label=<entropy = 0.0<br/>samples = 87<br/>value = [43.778, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
83 -> 85 ;
86 [label=<entropy = 0.0<br/>samples = 291<br/>value = [146.431, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
82 -> 86 ;
87 [label=<entropy = 0.0<br/>samples = 1131<br/>value = [569.117, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
69 -> 87 ;
88 [label=<X<SUB>17</SUB> &le; 3.5<br/>entropy = 0.76<br/>samples = 5325<br/>value = [2620.152, 9283.369]<br/>class = 1>, fillcolor="#71b9ec"] ;
44 -> 88 ;
89 [label=<X<SUB>4</SUB> &le; 1.5<br/>entropy = 0.65<br/>samples = 3421<br/>value = [1668.102, 8339.298]<br/>class = 1>, fillcolor="#61b1ea"] ;
88 -> 89 ;
90 [label=<X<SUB>28</SUB> &le; 4.5<br/>entropy = 0.815<br/>samples = 1718<br/>value = [848.392, 2517.524]<br/>class = 1>, fillcolor="#7cbeee"] ;
89 -> 90 ;
91 [label=<X<SUB>6</SUB> &le; -0.5<br/>entropy = 0.78<br/>samples = 1538<br/>value = [757.816, 2517.524]<br/>class = 1>, fillcolor="#75baed"] ;
90 -> 91 ;
92 [label=<entropy = 0.0<br/>samples = 104<br/>value = [52.333, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
91 -> 92 ;
93 [label=<X<SUB>0</SUB> &le; 0.5<br/>entropy = 0.758<br/>samples = 1434<br/>value = [705.484, 2517.524]<br/>class = 1>, fillcolor="#70b8ec"] ;
91 -> 93 ;
94 [label=<entropy = 0.0<br/>samples = 76<br/>value = [38.243, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
93 -> 94 ;
95 [label=<X<SUB>5</SUB> &le; 3.5<br/>entropy = 0.741<br/>samples = 1358<br/>value = [667.241, 2517.524]<br/>class = 1>, fillcolor="#6db7ec"] ;
93 -> 95 ;
96 [label=<entropy = 0.644<br/>samples = 825<br/>value = [402.055, 2045.488]<br/>class = 1>, fillcolor="#60b0ea"] ;
95 -> 96 ;
97 [label=<entropy = 0.942<br/>samples = 533<br/>value = [265.185, 472.036]<br/>class = 1>, fillcolor="#a8d4f4"] ;
95 -> 97 ;
98 [label=<entropy = 0.0<br/>samples = 180<br/>value = [90.576, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
90 -> 98 ;
99 [label=<X<SUB>5</SUB> &le; 4.5<br/>entropy = 0.539<br/>samples = 1703<br/>value = [819.71, 5821.774]<br/>class = 1>, fillcolor="#55abe9"] ;
89 -> 99 ;
100 [label=<X<SUB>15</SUB> &le; 0.5<br/>entropy = 0.531<br/>samples = 1658<br/>value = [797.066, 5821.774]<br/>class = 1>, fillcolor="#54aae9"] ;
99 -> 100 ;
101 [label=<X<SUB>27</SUB> &le; 3.5<br/>entropy = 0.523<br/>samples = 1618<br/>value = [776.938, 5821.774]<br/>class = 1>, fillcolor="#53aae8"] ;
100 -> 101 ;
102 [label=<X<SUB>23</SUB> &le; 4.5<br/>entropy = 0.623<br/>samples = 1011<br/>value = [491.624, 2674.869]<br/>class = 1>, fillcolor="#5dafea"] ;
101 -> 102 ;
103 [label=<entropy = 0.481<br/>samples = 440<br/>value = [209.834, 1809.47]<br/>class = 1>, fillcolor="#50a8e8"] ;
102 -> 103 ;
104 [label=<entropy = 0.804<br/>samples = 571<br/>value = [281.791, 865.399]<br/>class = 1>, fillcolor="#79bded"] ;
102 -> 104 ;
105 [label=<X<SUB>33</SUB> &le; 5.5<br/>entropy = 0.413<br/>samples = 607<br/>value = [285.313, 3146.905]<br/>class = 1>, fillcolor="#4ba6e7"] ;
101 -> 105 ;
106 [label=<entropy = 0.385<br/>samples = 521<br/>value = [243.045, 2989.56]<br/>class = 1>, fillcolor="#49a5e7"] ;
105 -> 106 ;
107 [label=<entropy = 0.745<br/>samples = 86<br/>value = [42.269, 157.345]<br/>class = 1>, fillcolor="#6eb7ec"] ;
105 -> 107 ;
108 [label=<entropy = 0.0<br/>samples = 40<br/>value = [20.128, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
100 -> 108 ;
109 [label=<entropy = 0.0<br/>samples = 45<br/>value = [22.644, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
99 -> 109 ;
110 [label=<X<SUB>26</SUB> &le; 3.5<br/>entropy = 1.0<br/>samples = 1904<br/>value = [952.051, 944.071]<br/>class = 0>, fillcolor="#fffefd"] ;
88 -> 110 ;
111 [label=<X<SUB>7</SUB> &le; 3.5<br/>entropy = 0.877<br/>samples = 601<br/>value = [297.893, 708.054]<br/>class = 1>, fillcolor="#8cc6f0"] ;
110 -> 111 ;
112 [label=<X<SUB>2</SUB> &le; 0.5<br/>entropy = 0.817<br/>samples = 487<br/>value = [240.529, 708.054]<br/>class = 1>, fillcolor="#7cbeee"] ;
111 -> 112 ;
113 [label=<X<SUB>20</SUB> &le; 1.5<br/>entropy = 0.199<br/>samples = 18<br/>value = [7.548, 236.018]<br/>class = 1>, fillcolor="#3fa0e6"] ;
112 -> 113 ;
114 [label=<entropy = 0.0<br/>samples = 9<br/>value = [4.529, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
113 -> 114 ;
115 [label=<entropy = 0.098<br/>samples = 9<br/>value = [3.019, 236.018]<br/>class = 1>, fillcolor="#3c9ee5"] ;
113 -> 115 ;
116 [label=<X<SUB>25</SUB> &le; 0.5<br/>entropy = 0.915<br/>samples = 469<br/>value = [232.981, 472.036]<br/>class = 1>, fillcolor="#9bcdf2"] ;
112 -> 116 ;
117 [label=<entropy = 0.0<br/>samples = 304<br/>value = [152.972, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
116 -> 117 ;
118 [label=<X<SUB>10</SUB> &le; 1.5<br/>entropy = 0.597<br/>samples = 165<br/>value = [80.008, 472.036]<br/>class = 1>, fillcolor="#5baee9"] ;
116 -> 118 ;
119 [label=<entropy = 0.983<br/>samples = 116<br/>value = [57.868, 78.673]<br/>class = 1>, fillcolor="#cbe5f8"] ;
118 -> 119 ;
120 [label=<entropy = 0.3<br/>samples = 49<br/>value = [22.141, 393.363]<br/>class = 1>, fillcolor="#44a3e6"] ;
118 -> 120 ;
121 [label=<entropy = 0.0<br/>samples = 114<br/>value = [57.365, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
111 -> 121 ;
122 [label=<X<SUB>20</SUB> &le; 3.5<br/>entropy = 0.834<br/>samples = 1303<br/>value = [654.157, 236.018]<br/>class = 0>, fillcolor="#eeae80"] ;
110 -> 122 ;
123 [label=<X<SUB>19</SUB> &le; 0.5<br/>entropy = 0.956<br/>samples = 779<br/>value = [390.482, 236.018]<br/>class = 0>, fillcolor="#f5cdb1"] ;
122 -> 123 ;
124 [label=<entropy = 0.0<br/>samples = 396<br/>value = [199.266, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
123 -> 124 ;
125 [label=<X<SUB>4</SUB> &le; 0.5<br/>entropy = 0.992<br/>samples = 383<br/>value = [191.215, 236.018]<br/>class = 1>, fillcolor="#d9ecfa"] ;
123 -> 125 ;
126 [label=<entropy = 0.0<br/>samples = 142<br/>value = [71.454, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
125 -> 126 ;
127 [label=<X<SUB>24</SUB> &le; 0.5<br/>entropy = 0.922<br/>samples = 241<br/>value = [119.761, 236.018]<br/>class = 1>, fillcolor="#9dcff2"] ;
125 -> 127 ;
128 [label=<entropy = 0.0<br/>samples = 81<br/>value = [40.759, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
127 -> 128 ;
129 [label=<entropy = 0.813<br/>samples = 160<br/>value = [79.002, 236.018]<br/>class = 1>, fillcolor="#7bbeee"] ;
127 -> 129 ;
130 [label=<entropy = 0.0<br/>samples = 524<br/>value = [263.676, 0.0]<br/>class = 0>, fillcolor="#e58139"] ;
122 -> 130 ;
}